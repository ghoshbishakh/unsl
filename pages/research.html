<!--
=========================================================
* Material Kit 2 - v3.0.2
=========================================================

* Product Page: https://www.creative-tim.com/product/material-kit
* Copyright 2022 Creative Tim (https://www.creative-tim.com)
* Licensed under MIT (https://www.creative-tim.com/license)
* Coded by Creative Tim

=========================================================

* The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. -->
<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <link rel="apple-touch-icon" sizes="76x76" href="../assets/img/apple-icon.png">
  <link rel="icon" type="image/png" href="../assets/img/favicon.png">
  <title>
    UbiNet@CSE,IITKGP
  </title>
  <!--     Fonts and icons     -->
  <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700,900|Roboto+Slab:400,700" />
  <!-- Nucleo Icons -->
  <link href="../assets/css/nucleo-icons.css" rel="stylesheet" />
  <link href="../assets/css/nucleo-svg.css" rel="stylesheet" />
  <!-- Font Awesome Icons -->
  <script src="https://kit.fontawesome.com/42d5adcbca.js" crossorigin="anonymous"></script>
  <!-- Material Icons -->
  <link href="https://fonts.googleapis.com/icon?family=Material+Icons+Round" rel="stylesheet">
  <!-- CSS Files -->
  <link id="pagestyle" href="../assets/css/material-kit.css?v=3.0.2" rel="stylesheet" />
</head>

<body class="inputs-sections">
  <!-- Navbar Transparent -->
  <nav class="navbar navbar-expand-lg position-absolute top-0 z-index-3 w-100 shadow-none my-3  navbar-transparent ">
    <div class="container">
      <a class="navbar-brand  text-white " href="../index.html" rel="tooltip" title="Designed and Coded by Creative Tim" data-placement="bottom" target="_blank">
        <b>UbiNet@CSE,IITKGP</b>
      </a>
      <button class="navbar-toggler shadow-none ms-2" type="button" data-bs-toggle="collapse" data-bs-target="#navigation" aria-controls="navigation" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon mt-2">
          <span class="navbar-toggler-bar bar1"></span>
          <span class="navbar-toggler-bar bar2"></span>
          <span class="navbar-toggler-bar bar3"></span>
        </span>
      </button>
      <div class="collapse navbar-collapse w-100 pt-3 pb-2 py-lg-0 ms-lg-12 ps-lg-5" id="navigation">
        <ul class="navbar-nav navbar-nav-hover ms-auto">
          <li class="nav-item dropdown dropdown-hover mx-2 ms-lg-6">
            <a class="nav-link ps-2 d-flex justify-content-between cursor-pointer align-items-center" href="../index.html">
              <i class="material-icons opacity-6 me-2 text-md">dashboard</i>
              Home
              <!--<img src="assets/img/down-arrow-white.svg" alt="down-arrow" class="arrow ms-2 d-lg-block d-none">
              <img src="assets/img/down-arrow-dark.svg" alt="down-arrow" class="arrow ms-2 d-lg-none d-block">-->
            </a>
          </li>
          <li class="nav-item dropdown dropdown-hover mx-2">
            <a class="nav-link ps-2 d-flex justify-content-between cursor-pointer align-items-center" href="../publications/index.html">
              <i class="material-icons opacity-6 me-2 text-md">view_day</i>
              Publications
              <!--<img src="assets/img/down-arrow-white.svg" alt="down-arrow" class="arrow ms-2 d-lg-block d-none">-->
              <!--<img src="assets/img/down-arrow-dark.svg" alt="down-arrow" class="arrow ms-2 d-lg-none d-block">-->
            </a>
          </li>
          <li class="nav-item dropdown dropdown-hover mx-2">
            <a class="nav-link ps-2 d-flex justify-content-between cursor-pointer align-items-center" id="dropdownMenuDocs" data-bs-toggle="dropdown" aria-expanded="false">
              <i class="material-icons opacity-6 me-2 text-md">article</i>
              Research Areas
              <img src="../assets/img/down-arrow-white.svg" alt="down-arrow" class="arrow ms-2 d-lg-block d-none">
              <img src="../assets/img/down-arrow-dark.svg" alt="down-arrow" class="arrow ms-2 d-lg-none d-block">
            </a>
            <ul class="dropdown-menu dropdown-menu-animation dropdown-menu-end dropdown-md dropdown-md-responsive mt-0 mt-lg-3 p-3 border-radius-lg" aria-labelledby="dropdownMenuDocs">
              <div class="d-none d-lg-block">
                <ul class="list-group">
                  <li class="nav-item list-group-item border-0 p-0">
                    <a class="dropdown-item py-2 ps-3 border-radius-md" href="$">
                      <h6 class="dropdown-header text-dark font-weight-bolder d-flex justify-content-cente align-items-center p-0">Computer Human Interaction</h6>
                      <span class="text-sm">Assistive Systems, Human Machine Interfacing</span>
                    </a>
                  </li>
                  <li class="nav-item list-group-item border-0 p-0">
                    <a class="dropdown-item py-2 ps-3 border-radius-md" href="#">
                      <h6 class="dropdown-header text-dark font-weight-bolder d-flex justify-content-cente align-items-center p-0">Sensing</h6>
                      <span class="text-sm">Smartphones, Wearables, Sensors</span>
                    </a>
                  </li>
                  <li class="nav-item list-group-item border-0 p-0">
                    <a class="dropdown-item py-2 ps-3 border-radius-md" href="#">
                      <h6 class="dropdown-header text-dark font-weight-bolder d-flex justify-content-cente align-items-center p-0">Distributed Systems</h6>
                      <span class="text-sm">Cloud, Edge, Blockchains</span>
                    </a>
                  </li>
                  <li class="nav-item list-group-item border-0 p-0">
                    <a class="dropdown-item py-2 ps-3 border-radius-md" href="#">
                      <h6 class="dropdown-header text-dark font-weight-bolder d-flex justify-content-cente align-items-center p-0">Networking</h6>
                      <span class="text-sm">Protocols, Quality, Applications</span>
                    </a>
                  </li>
                </ul>
              </div>
              <div class="row d-lg-none">
                <div class="col-md-12 g-0">
                  <a class="dropdown-item py-2 ps-3 border-radius-md" href="#">
                    <h6 class="dropdown-header text-dark font-weight-bolder d-flex justify-content-cente align-items-center p-0">Computer Human Interaction</h6>
                    <span class="text-sm">Assistive Systems, Human Machine Interfacing</span>
                  </a>
                  <a class="dropdown-item py-2 ps-3 border-radius-md" href="#">
                    <h6 class="dropdown-header text-dark font-weight-bolder d-flex justify-content-cente align-items-center p-0">Sensing</h6>
                    <span class="text-sm">Smartphones, Wearables, Sensors</span>
                  </a>
                  <a class="dropdown-item py-2 ps-3 border-radius-md" href="#">
                    <h6 class="dropdown-header text-dark font-weight-bolder d-flex justify-content-cente align-items-center p-0">Distributed Systems</h6>
                    <span class="text-sm">Cloud, Edge, Blockchains</span>
                  </a>
                  <a class="dropdown-item py-2 ps-3 border-radius-md" href="#">
                    <h6 class="dropdown-header text-dark font-weight-bolder d-flex justify-content-cente align-items-center p-0">Networking</h6>
                    <span class="text-sm">Protocols, Quality, Applications</span>
                  </a>
                </div>
              </div>
            </ul>
          </li>
          <li class="nav-item dropdown dropdown-hover mx-2">
            <a class="nav-link ps-2 d-flex justify-content-between cursor-pointer align-items-center" href="./projects.html">
              <i class="fa fa-github me-1"></i>
              Sponsored Projects
              <!--<img src="assets/img/down-arrow-white.svg" alt="down-arrow" class="arrow ms-2 d-lg-block d-none">
              <img src="assets/img/down-arrow-dark.svg" alt="down-arrow" class="arrow ms-2 d-lg-none d-block">-->
            </a>
          </li>
        </ul>
      </div>
    </div>
  </nav>
  <!-- End Navbar -->
   <!-- -------- START HEADER 7 w/ text and video ------- -->
  <header class="bg-gradient-dark">
    <div class="page-header min-vh-50" style="background-image: url('../assets/img/bgiit.jpg');">
      <span class="mask bg-gradient-dark opacity-6"></span>
      <div class="container">
        <div class="row justify-content-center">
          <div class="col-lg-8 text-center mx-auto my-auto">
            <h1 class="text-white">Research @ Ubiquitous Networked Systems Lab</h1>
            <!-- <p class="lead mb-4 text-white opacity-8">We’re constantly trying to push the boundaries of sensing and systems research. Come along if you share the same ambition.</p>
            <button class="btn bg-white text-dark">Research Highlights</button>
            <h6 class="text-white mb-2 mt-5">Follow us on</h6>
            <div class="d-flex justify-content-center">
              <a href="#"><i class="fab fa-facebook text-lg text-white me-4"></i></a>
              <a href="#"><i class="fab fa-instagram text-lg text-white me-4"></i></a>
              <a href="#"><i class="fab fa-twitter text-lg text-white me-4"></i></a>
              <a href="#"><i class="fab fa-google-plus text-lg text-white"></i></a>
            </div> -->
          </div>
        </div>
      </div>
    </div>
  </header>
  <!-- -------- END HEADER 7 w/ text and video ------- -->
  <div class="container mt-8">
    <div class="row">
      <div class="col-lg-12 mx-auto">
        <!--<h2>Research Focus @ UbiNet</h2>-->
        <hr>
          
        <!-- Sensing -->
          
        <div class="position-relative border-radius-xl overflow-hidden shadow-lg mb-7">
          <div class="container border-bottom">
                <h2>Sensing</h2>
          </div>
          <div class="tab-content tab-space p-3">
            <p> Pervasive sensing is the primary focus of our research group. We sense everything, humans and the environment, and with different modalities, like the locomotive, acoustic, RF, medical, etc., under different infrastructures, like active and passive sensing, wearables, fixed-infrastructure, sensing, etc. The objective is to develop ubiquitous applications that can be leveraged through low-cost sensing infrastructure. We use different technologies, like signal processing, machine learning, deep learning, etc., from the algorithmic perspective to meet our goals. Some of our recent exciting projects are as follows.</p>
            
            <h5>Smart Transportation: Sensing the Road, the Vehicle, and the Driver</h5>
              <p>Road travel in developing countries, particularly in the Indian subcontinent, is very sporadic because of multiple socio-economic factors. The roads are bumpy in many places; infrastructure is not very good, the streets are congested due to heavy traffic, and so on. We develop pervasive sensing modalities to sense the road, the transport infrastructure, and the driver. One critical issue is understanding various points of interest (PoIs) on the road, which affect travel. We use smartphone-based crowdsensing, leveraging the embedded sensors on today's smartphones like IMU, GPS, etc., to capture various PoIs and tag them over the map. One of the crucial issues is monitoring a driver's driving behavior and how the driver interacts with various landmarks on the road, like speed breakers, potholes, turns, etc. We also aim to understand the driving behavior and its impact on different maneuvers taken by the driver. Collectively, we target the lifestyle of citizens on the road to develop assistive technologies to support them during their daily commute.<br><br>
                <iframe width="380" height="212" src="https://www.youtube.com/embed/vgzzV-UNFfE" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>   
                <iframe width="380" height="212" src="https://www.youtube.com/embed/a12gc6Bdq2M" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
              </p>
              <h5>Human Sensing: Activity Recognition and Annotation</h5>
              <p>Human activity recognition (HAR) has been one of the essential building blocks behind various pervasive applications. We are working on developing lightweight and cost-effective approaches for HAR, starting from macro-activities, like walking, running, writing on a board, meeting group detection, etc., to micro and fine-grained activities like cooking in a smart-home scenario. We use various modalities, like IMU, acoustic, RF, etc., for inferring the activities. Another area of our prime focus is activity annotation. The typical HAR models work in a supervised environment; therefore, they need a massive amount of labeled data to train the models. The question is, how do we label or annotate this data? We work to develop a robust and automated approach to use auxiliary sensing modalities, like acoustic, to label the IMU data for activity recognition. This is a challenging problem as the method does not have any prior knowledge; therefore, it needs to work in an unsupervised way. We also work on understanding the granularity and informativeness of these labels and how the generated labels can contribute to the development of large-scale activity recognition models.<br><br> 
               <iframe width="380" height="212" src="https://www.youtube.com/embed/fPeB20pJPEs" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
               <iframe width="380" height="212" src="https://www.youtube.com/embed/-OdEqAd6E8s" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
               <iframe width="380" height="212" src="https://www.youtube.com/embed/_zVN5e9N6o8" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
               <iframe width="380" height="212" src="https://www.youtube.com/embed/KAuUhk3PtWk" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
              </p>
              <h5>Environment Sensing: Making the World a Smart Place to Live</h5>
              <p> Of late, we started working on sensing the environment. <a href="https://www.iqair.com/in-en/world-most-polluted-cities" target="_blank">Six out of top 10 polluted cities in the world are from India.</a> We aim to develop a low-cost, portable pollution monitoring device that can help individuals sense the environment for the presence of different pollutants in outdoor and indoor environments. We also work on designing an efficient mechanism for deciding the placement of pollution monitoring devices in an indoor setup, understand the impact of pollutants on the cognitive and behavioral aspects of humans, and understand the impact of several indoor activities on the pollution level of the room.    
              </p>
              <h5>Affective Sensing: Understand Human Behavior from Passive Sensing</h5>
              <p>There has been a recent development in designing applications based on behavioral HCI, for example, emotion-aware music player, facial expression-based device control, etc. Recently we started working towards exploring passive sensing technologies, such as mmWave sensing, acoustic sensing, etc., towards understanding the user's facial expressions, emotions, and behavioral aspects. Typical, different facial expressions result from a set of Action Units (AU) (facial muscle movements). Such facial muscle movements are the building blocks of expressions and can be categorized under ocular (around eye region), nasal (around nose region), and oral (around mouth area) groups. For example, a particular expression, say "Happiness," is a combination of facial muscle movements, majorly around the oral region and subtly around the ocular and nasal areas. We aim to use various passive sensing technologies, such as acoustic sensing, mmWave radar-based sensing, smartphone-embedded LiDAR, etc., to sense the user's facial expression.</p>
          </div>
        </div>
        
        <!-- HCI -->
          
        <div class="position-relative border-radius-xl overflow-hidden shadow-lg mb-7">
          <div class="container border-bottom">
                <h2>Computer Human Interaction</h2>
          </div>
          <div class="tab-content tab-space p-3">
            <p> The prime focus of our lab is to develop pervasive and ubiquitous systems for computer-human interactions. Towards this goal, we use interactive sensing modalities, like video, audio, RF sensing, smartphone-based sensing, smart wearables, etc., to design assistive systems for the common masses, particularly for the regions of underdeveloped and developing countries. Some of our current projects are as follows. </p>
            
            <h5>Smart Interface for Virtual Meeting Apps</h5>
              <p>For over two decades, video conferencing has been a productive approach for exchanging conversations between multiple participants through a digital online mode. During the COVID-19 pandemic and beyond, it became a necessity rather than an option when almost every meeting, be it a classroom teaching or a business meeting, is being conducted in the virtual mode through various online video conferencing platforms. Nevertheless, there has been a serious concern about these meetings' quality due to the lack of engagement from the participants, particularly in the business meetings or the classroom teachings, educational seminars, etc. Many participants tend to be passive during the sessions, mainly when they find other more exciting activities, like reading a storybook or an article over the Internet or browsing through their social networking feeds. Consequently, attending the meeting becomes merely a proof of participation, like giving the class attendance while not following the lectures!<br>
              We work on developing intelligent interfaces for online meeting attendees to monitor their cognitive involvement in the meetings. We explore the behavioral patterns of individuals during online discussions and then use active and passive sensing modalities, like video, RF, acoustics, wearables, etc., to see whether the participant is cognitively involved in the meeting's discussions.<br><br>
                  <iframe width="380" height="212" src="https://www.youtube.com/embed/edMFZH90iB8" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
              </p> 
              
            <h5>Mobile Interface Design for Challenged and Disabled Peoples</h5>
              <p>Today's smartphones are getting smarter; however, they might not be absolutely friendly for challenged and disabled people. For example, people with medical issues like dactylitis, sarcopenia, and joint pains might have difficulty typing using a smartphone's conventional QWERTY soft-keyboard. Existing gaze or voice-based approaches do not work well without commercial trackers or noisy environments. We develop intelligent interfaces to help such peoples interact with the smartphone seamlessly, using alternate modalities such as head gestures, visual cues, etc. This is particularly challenging as the method must be efficient enough to run over a smartphone. We develop lightweight tracking techniques by leveraging online learning to solve this problem. <br><br>
                  <iframe width="380" height="212" src="https://www.youtube.com/embed/eXWbPSuuEag" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
              </p>
          </div>
        </div>
          
        <!-- Distributed Systems -->
          <div class="position-relative border-radius-xl overflow-hidden shadow-lg mb-7">
          <div class="container border-bottom">
                <h2>Distributed Systems</h2>
          </div>
          <div class="tab-content tab-space p-3">
            <p>
              Large-scale pervasive systems are likely to be distributed. We study reliability, fault-tolerance, system vulnerability assessment, etc., for large-scale distributed systems. From the application perspective, we work for developing blockchain-assisted systems and utilizing the concepts of blockchain and decentralized web for secured data and asset transfer among multiple consortiums of users. Our research in distributed systems also focuses on various aspects of cloud and edge computing, like resource allocation, edge-cloud orchestration, containerized application development, deployment, etc. A few of our recent researches are summarized next. 
            </p>
            
              <h5>Edge Networking and Resource Management at the Edge</h5>
              <p> Lorem Ipsum is simply dummy text of the printing and typesetting industry. Lorem Ipsum has been the industry's standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book. It has survived not only five centuries, but also the leap into electronic typesetting, remaining essentially unchanged. It was popularised in the 1960s with the release of Letraset sheets containing Lorem Ipsum passages, and more recently with desktop publishing software like Aldus PageMaker including versions of Lorem Ipsum.</p>
=======
            
            <p>
              Centralization of control and trust on a single authoratitive entity vastly reduces the trustworthiness of any sytem as a whole.
              A major focus of our research on distributed systems is to build decentralized systems where the stakeholders maintain control with themselves and 
              the trust basis for any operation is not centralized. We primarily focus on the interoperability aspect of decentralized systems, mainly involving permissioned distribute ledger technologies (DLTs).
            </p>
            
            
            <h5>Decentralized Service Providing Platforms</h5>
            <p>
            With the increasing adoption of private blockchain platforms, consortia operating in various sectors such as trade, finance, logistics, etc., 
            are becoming common. Despite having the benefits of a completely decentralized architecture which supports transparency and distributed control, 
            existing private blockchains limit the data, assets, and processes within its closed boundary, which restricts secure and verifiable service provisioning to
             the end-consumers. Thus, platforms such as e-commerce with multiple sellers or cloud federation with a collection of cloud service providers cannot 
             be decentralized with the existing blockchain platforms. The focus of this work is to develop a decentralized framework whose primary objective is 
             interfacing private blockchain with end-users by leveraging the unique combination of public and private blockchain platforms through interoperation. 
             We have taken up the use case of decentralized cloud federations, we have demonstrated the viability of some of our solutions. 
             We build our prototypes primarily with standard platforms such as Ethereum and Hyperledger Fabric.
            </p>

            
              <h5>Identity Management for Blockchain Networks</h5>
              <p>
                The industry is seeing more and more adoption of permissioned blockchain networks for transparent yet secure and trusted coordination 
                between different business entities. However, this has resulted in the formation of isolated blockchain consortiums which have no standard protocol
                for interoperating with one another.
                Interoperation for data sharing between permissioned blockchain networks relies on networks' abilities to 
                independently authenticate requests and validate proofs accompanying the data; these typically contain digital signatures. 
                This requires counterparty networks to know the identities and certification chains of each other's members, establishing a common trust basis rooted in identity. 
                In this work we are building an architecture and set of protocols for distributed identity management across permissioned blockchain networks to establish a trust basis for cross-network data sharing.
                We incorporate self-sovereign decentralized identities (SSI and DIDs) in DLT components through which they obtain privacy-preserving verifiable membership credentials.
                During interoperation, networks can securely and dynamically discover each others' latest membership lists and members' credentials.
              </p>

              <h5>Privacy Preserving Negotiation of Common Trust Basis</h5>
              
                <p>
                  Interoperation between permissioned consortium blockchain networks relies on their abilities to discover and validate the identities of each others’ participant organizations. 
                  In that aspect, organizations may possess self-sovereign decentralized identities and verifiable credentials issued by well-known certification authorities. 
                  However, two mutually untrusting networks of organizations can establish a basis for interoperation only if they have one or more certification authorities in common.
                  Yet, for privacy reasons, neither of them may want to expose a priori their entire lists of authorities, necessitating a negotiation process through which common authorities can be identified.
                  In this work, we analyze this negotiation problem, and are developing protocols through which two mutually untrusting parties can find out a common trust anchor in the form of a verifiable credential issuer without revealing any of their trust anchors which are not common between them to one another.
                </p>
          </div>
        </div>
              
        <!-- Networking -->
        <div class="position-relative border-radius-xl overflow-hidden shadow-lg mb-7">
          <div class="container border-bottom">
                <h2>Networking</h2>
          </div>
          <div class="tab-content tab-space p-3">
            <p> The network plays a significant role in the design and development of today's large-scale distributed pervasive systems. We broadly work on network measurement, protocol design, and network-application integration. Our broad focus is to make the Internet ubiquitous and friendly for inter-connectivity among millions of devices. We list a few of our current projects here. </p>
            
            <h5>Video Streaming over Ubiquitous Internet</h5>
              <p>Video consumes the majority of the traffic on today's Internet. Users demand high Quality of Experience (QoE) from the streaming service providers; however, it is challenging to monitor and understand the state of the underlying network to stream the videos an optimal quality. We work towards making the streaming applications smarter by incorporating intelligence in the network. Such an intelligent integration between the network and the application can serve many purposes, like optimizing the video QoE, minimizing the energy consumption during video streaming, optimizing network usage, and so on. We explore specific lower-layer network properties, like the connection states, signaling information, bandwidth history, etc., to develop an online learning mechanism to optimize the video data download from the streaming server.<br><br>
              <iframe width="380" height="212" src="https://www.youtube.com/embed/3Rbiz6igcd8" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
              </p>  
              
              <h5>Energy-efficient Networking</h5>
              <p>
              Next-generation 5G New Radio (NR) cellular networks operating at mmWave frequencies are targeted to support diverse use cases, such as enhanced Mobile Broadband (eMBB), massive machine-type communications (mMTC), ultra-reliable and low latency communications (URLLC), etc. Energy-Efficiency is one of the key performance indicators for NR technology. User Equipment (UE) battery life significantly impacts the Quality of Experience (QoE) of the UE. Thus the 5G NR standard is designed to have great flexibility in network operation modes to adapt to different requirements and trade-offs. 3GPP, in its 5G technical specification release, has proposed various power-saving schemes such as connected mode Discontinuous Reception (cDRX), RRC_INACTIVE state, etc. Today's ubiquitous applications need to leverage the energy-efficiency features supported by the underlying network. We primarily work in designing energy-efficient network interfaces by exploiting the application characteristics. More specifically, we target combining sensing and communication with running the applications seamlessly with fewer carbon footprints. On this front, we also contribute to developing open-source tools and simulation frameworks. <br><br>
                  <iframe width="380" height="212" src="https://www.youtube.com/embed/tmoCvKiM_Dk" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
                  <iframe width="380" height="212" src="https://www.youtube.com/embed/4m44MYRYiio" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
                  <iframe width="380" height="212" src="https://www.youtube.com/embed/U0C_mXrLexs" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
              </p>
          </div>
        </div>

      </div>
    </div>
  </div>
  <!-- -------- START FOOTER 3 w/ COMPANY DESCRIPTION WITH LINKS & SOCIAL ICONS & COPYRIGHT ------- -->
  <footer class="footer py-5">
    <div class="container">
      <div class="row">
        <div class="col-8 mx-auto text-center mt-1">
          <p class="mb-0 text-secondary">
            Copyright © <script>
              document.write(new Date().getFullYear())
            </script> UbiNet@CSE,IITKGP
          </p>
        </div>
      </div>
    </div>
  </footer>
  <!-- -------- END FOOTER 3 w/ COMPANY DESCRIPTION WITH LINKS & SOCIAL ICONS & COPYRIGHT ------- -->
  <!--   Core JS Files   -->
  <script src="../assets/js/core/popper.min.js" type="text/javascript"></script>
  <script src="../assets/js/core/bootstrap.min.js" type="text/javascript"></script>
  <script src="../assets/js/plugins/perfect-scrollbar.min.js"></script>
  <script src="../assets/js/plugins/prism.min.js"></script>
  <script src="../assets/js/plugins/highlight.min.js"></script>
  <!--  Plugin for Parallax, full documentation here: https://github.com/wagerfield/parallax  -->
  <script src="../assets/js/plugins/parallax.min.js"></script>
  <!-- Control Center for Material UI Kit: parallax effects, scripts for the example pages etc -->
  <!--  Google Maps Plugin    -->
  <script src="https://maps.googleapis.com/maps/api/js?key=AIzaSyDTTfWur0PDbZWPr7Pmq8K3jiDp0_xUziI"></script>
  <script src="../assets/js/material-kit.min.js?v=3.0.2" type="text/javascript"></script>
</body>

</html>
